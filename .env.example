# AI Provider Configuration
# Choose your AI provider by configuring the appropriate section
# NOTE: In development mode, the app automatically uses a proxy to avoid CORS issues

# LM Studio Configuration (default)
VITE_OPENAI_BASE_URL=http://127.0.0.1:1234/v1
VITE_OPENAI_API_KEY=lm-studio
VITE_OPENAI_MODEL=lmstudio

# Ollama Configuration (alternative)
# Uncomment these and comment out LM Studio config above to use Ollama
# VITE_OLLAMA_BASE_URL=http://127.0.0.1:11434/v1
# VITE_OLLAMA_API_KEY=ollama
# VITE_OLLAMA_MODEL=gemma3:4b

# Production builds will use the URLs above directly
# Development mode automatically proxies requests to avoid CORS issues