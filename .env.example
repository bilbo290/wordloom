# AI Provider Configuration
# Choose your AI provider by configuring the appropriate section
# NOTE: In development mode, the app automatically uses a proxy to avoid CORS issues

# Ollama Configuration (default)
VITE_OLLAMA_BASE_URL=http://127.0.0.1:11434/v1
VITE_OLLAMA_API_KEY=ollama
VITE_OLLAMA_MODEL=gemma3:4b

# LM Studio Configuration (alternative)
# Uncomment these and comment out Ollama config above to use LM Studio
# VITE_OPENAI_BASE_URL=http://127.0.0.1:1234/v1
# VITE_OPENAI_API_KEY=lm-studio
# VITE_OPENAI_MODEL=lmstudio

# Production builds will use the URLs above directly
# Development mode automatically proxies requests to avoid CORS issues